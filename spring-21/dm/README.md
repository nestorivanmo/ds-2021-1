# Massive Data I - 0602

The main objective of this course is learning algorithms to be used when data is so 
big (hundreds of GB) that it cannot be stored in a computer's personal memory. 
Thus, we look into different options for handling this type of problems, such as: 

- Distributed File Systems
  - Hadoop HDFS
  - Google DFS
- MapReduce algorithms
  - Implemented in PySpark, for example. 
- Hash Functions