---
title: "Práctica 9: Teorema Central del Límite"
author: "Martínez Ostoa Néstor LCD 32"
date: "11/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Simulación de una variale $N(0,1)$ a partir de binomiales $Bin(n,p)$
Utilizando el teorema del límite central $$\frac{\sum_{i=1}^{k}X_i\; -k\mu}{\sqrt{k\sigma ^2}}$$ generamos ocho histogramas de $10,000$ variables aleatorias normales con los parámetros mostrados en las figuras siguientes. 

El código utilizado para generar una variable $Z$ fue el siguiente:
``` {r}
Z <- function(n, p, k) {
  bin <- rbinom(n, k, p)
  mu_k <- k*n*p
  sigma_k <- sqrt(k*n*p*(1-p))
  z <- (sum(bin) - mu_k) / sigma_k
  return (z);
}
```

El código utilizado para hacer la comparación entre la distribución normal y la aproximación por medio de la binomial fue el siguiente:
``` {r}
bin_vs_norm <- function(N, n, p, k) {
  Z_vec <- c()
  for (i in 1:N) {
    Z_vec <- c(Z_vec, Z(n, p, k))
  }
  hist(Z_vec, probability = TRUE, xlab = 'X', ylab = 'Z',
       main = paste('N(0,1) ~ Bin(',n,',',p,')\n k =', k));
  sop <- seq(-6, 6, length.out=1000)
  par(new = TRUE)
  lines(sop, dnorm(sop))
}
```

Los histogramas son los siguientes, todos consideran $N = 10000$:
$n=10, p=0.5, k=10$
``` {r fig.width=5, fig.height = 3.5, fig.align='center'}
N = 10000
bin_vs_norm(N,10, 0.5, 10)
```
$n=10, p=0.5, k=20$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.5, 20)
```

$n=10, p=0.5, k=100$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.5, 100)
```

$n=10, p=0.5, k=1000$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.5, 1000)
```

$n=10, p=0.99, k=10$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.99, 10)
```

$n=10, p=0.99, k=20$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.99, 20)
```

$n=10, p=0.99, k=100$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.99, 100)
```

$n=10, p=0.99, k=1000$
```{r fig.width=5, fig.height = 3.5, fig.align='center'}
bin_vs_norm(N,10, 0.99, 1000)
```

## 2. Velocidad de convergencia
De las gráficas anteriores vemos con facilidad que $Ber(n, 0.5)$ converge más rápido que $Ber(n, 0.99)$. Lo anterior lo atribuyo a dos razones principales: 

1. Una variable aleatoria con distribución Bernoulli tiene como esperanza $E(X) = np$ por lo que sin importar la $n$, una $p$ mayor o menor que $0.5$ siempre taradará más en converger que $p=0.5$ ues su valor esperado está más alejado del valor esperado de la distribución $N(0,1)$ que tiene un valor medio de $0.5$. 
2. Por otro lado, vemos que para $n$ suficientemente grande, la distribución $Ber(1000, 0.99)$ sí converge con mayor precisión a la $N(0,1)$. El hecho de que eventualmente la distribución Bernoulli converga se debe a la ley de los grandes números que nos indica que para una cantidad grande de experimentos, la media de esos experimentos tenderá al valor esperado, en este caso, $0.5$. 
